{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz5mmOdOHznl"
      },
      "source": [
        "# Counterfactuals benchmark on tabular datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYNbfZ4CbwI_",
        "outputId": "a152bcac-e593-4f83-e9b5-ffb9412f9cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "BASE_PATH = \"/gdrive/My Drive/counterfactuals\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7sVjpCaH3yD"
      },
      "source": [
        "## Imports and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tW1SdKmbrbj",
        "outputId": "eb57f82e-de9d-4046-de2d-e154bdea3863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://github.com/SeldonIO/alibi.git /tmp/pip-req-build-a1d2dpc5\n",
            "Alibi version: 0.5.6dev\n",
            "Is TensorFlow running in eager execution mode? -----→ False\n",
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install the dev version of the Alibi package\n",
        "!pip install git+https://github.com/SeldonIO/alibi.git > /dev/null\n",
        "from alibi import __version__ as alibi_version\n",
        "print(f\"Alibi version: {alibi_version}\")\n",
        "import logging\n",
        "\n",
        "alibi_logger = logging.getLogger(\"alibi\")\n",
        "alibi_logger.setLevel(\"CRITICAL\")\n",
        "\n",
        "import tensorflow as tf\n",
        "# Disabling eager execution because Alibi is not compatible with it\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "print(f\"Is TensorFlow running in eager execution mode? -----→ {tf.executing_eagerly()}\")\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aJpXl3siWZr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "if not os.path.exists(BASE_PATH):\n",
        "    os.makedirs(BASE_PATH)\n",
        "os.chdir(BASE_PATH)\n",
        "\n",
        "date = datetime.now().strftime('%Y-%m-%d')\n",
        "EXPERIMENT_PATH = f\"{BASE_PATH}/diabetes_{date}\"\n",
        "MODELS_EXPERIMENT_PATH = f\"{BASE_PATH}/diabetes_2020-09-09\"\n",
        "if not os.path.exists(EXPERIMENT_PATH):\n",
        "    os.makedirs(EXPERIMENT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Ne3HvYI8dv"
      },
      "source": [
        "## Data import and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "mAPAZpVUiks-",
        "outputId": "f7628cfa-2bd6-4c90-e027-d90f0ecf58b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>Age</th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>39</td>\n",
              "      <td>43.4</td>\n",
              "      <td>93</td>\n",
              "      <td>72</td>\n",
              "      <td>100</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>1.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>20</td>\n",
              "      <td>30.8</td>\n",
              "      <td>102</td>\n",
              "      <td>94</td>\n",
              "      <td>44</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>0.400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0</td>\n",
              "      <td>22.5</td>\n",
              "      <td>125</td>\n",
              "      <td>0</td>\n",
              "      <td>96</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>641</th>\n",
              "      <td>0</td>\n",
              "      <td>34.3</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>0.303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>19</td>\n",
              "      <td>25.8</td>\n",
              "      <td>166</td>\n",
              "      <td>175</td>\n",
              "      <td>72</td>\n",
              "      <td>51</td>\n",
              "      <td>5</td>\n",
              "      <td>0.587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     SkinThickness   BMI  Glucose  ...  Age  Pregnancies  DiabetesPedigreeFunction\n",
              "379             39  43.4       93  ...   35            0                     1.021\n",
              "741             20  30.8      102  ...   26            3                     0.400\n",
              "102              0  22.5      125  ...   21            0                     0.262\n",
              "641              0  34.3      128  ...   24            4                     0.303\n",
              "14              19  25.8      166  ...   51            5                     0.587\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import pickle\n",
        "import time\n",
        "from matplotlib import offsetbox\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "INITIAL_CLASS = 0\n",
        "DESIRED_CLASS = 1\n",
        "N_CLASSES = 2\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "tf.random.set_seed(2020)\n",
        "np.random.seed(2020)\n",
        "\n",
        "# Pima indians Diabetes dataset\n",
        "# https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
        "df = pd.read_csv(f\"{BASE_PATH}/diabetes.csv\", index_col=False)\n",
        "target_column = \"Outcome\"\n",
        "immutable_features = {\"Pregnancies\", \"DiabetesPedigreeFunction\", \"Age\"}\n",
        "\n",
        "features = set(df.columns) - {target_column}\n",
        "mutable_features = features - immutable_features\n",
        "features = list(mutable_features) + list(immutable_features)\n",
        "\n",
        "x = df[features]\n",
        "y = df[target_column].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[features].values, y, test_size=0.2)\n",
        "\n",
        "standard_scaler = StandardScaler()\n",
        "X_train = standard_scaler.fit_transform(X_train)\n",
        "X_test = standard_scaler.transform(X_test)\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "df[features].sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTcm3LgfKEtl"
      },
      "outputs": [],
      "source": [
        "def compute_reconstruction_error(x, autoencoder):\n",
        "    \"\"\"Compute the reconstruction error for a given autoencoder and data points.\"\"\"\n",
        "    preds = autoencoder.predict(x)\n",
        "    preds_flat = preds.reshape((preds.shape[0], -1))\n",
        "    x_flat = x.reshape((x.shape[0], -1))\n",
        "    return np.linalg.norm(x_flat - preds_flat, axis=1)\n",
        "\n",
        "def format_metric(metric):\n",
        "    \"\"\"Return a formatted version of a metric, with the confidence interval.\"\"\"\n",
        "    return f\"{metric.mean():.3f} ± {1.96*metric.std()/np.sqrt(len(metric)):.3f}\"\n",
        "\n",
        "def compute_metrics(samples, counterfactuals, latencies, classifier, autoencoder,\n",
        "                    batch_latency=None):\n",
        "    \"\"\" Summarize the relevant metrics in a dictionary. \"\"\"\n",
        "    reconstruction_error = compute_reconstruction_error(counterfactuals, autoencoder)\n",
        "    delta = np.abs(samples-counterfactuals)\n",
        "    l1_distances = delta.reshape(delta.shape[0], -1).sum(axis=1)\n",
        "    prediction_gain = (\n",
        "        classifier.predict(counterfactuals)[:, DESIRED_CLASS] - \n",
        "        classifier.predict(samples)[:, DESIRED_CLASS]\n",
        "    )\n",
        "\n",
        "    metrics = dict()\n",
        "    metrics[\"reconstruction_error\"] = format_metric(reconstruction_error)\n",
        "    metrics[\"prediction_gain\"] = format_metric(prediction_gain)\n",
        "    metrics[\"sparsity\"] = format_metric(l1_distances)\n",
        "    metrics[\"latency\"] = format_metric(latencies)\n",
        "    batch_latency = batch_latency if batch_latency else sum(latencies)\n",
        "    metrics[\"latency_batch\"] = f\"{batch_latency:.3f}\"\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def save_experiment(method_name, samples, counterfactuals, latencies, \n",
        "                    batch_latency=None):\n",
        "    \"\"\"Create an experiment folder and save counterfactuals, latencies and metrics.\"\"\"\n",
        "    if not os.path.exists(f\"{EXPERIMENT_PATH}/{method_name}\"):\n",
        "        os.makedirs(f\"{EXPERIMENT_PATH}/{method_name}\")   \n",
        "\n",
        "    np.save(f\"{EXPERIMENT_PATH}/{method_name}/counterfactuals.npy\", counterfactuals)\n",
        "    np.save(f\"{EXPERIMENT_PATH}/{method_name}/latencies.npy\", latencies)\n",
        "\n",
        "    metrics = compute_metrics(samples, counterfactuals, latencies, classifier, autoencoder)\n",
        "    json.dump(metrics, open(f\"{EXPERIMENT_PATH}/{method_name}/metrics.json\", \"w\"))\n",
        "    pprint(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ISlxhmjvycC"
      },
      "source": [
        "## Train classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmw26uWLiw2c",
        "outputId": "b89cf614-ecd1-4638-9c6e-0c91a4d81f1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training: loss=0.4360, accuracy=0.7964\n",
            "Validation: loss=0.4581, accuracy=0.7727\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Add, Input, ActivityRegularization\n",
        "from tensorflow.keras import Model, optimizers, regularizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "tf.random.set_seed(2020)\n",
        "np.random.seed(2020)\n",
        "\n",
        "def create_classifier(input_shape):\n",
        "    \"\"\"Define and compile a neural network binary classifier.\"\"\" \n",
        "    model = Sequential([\n",
        "        Dense(20, activation='relu', input_shape=input_shape),\n",
        "        Dense(20, activation='relu'),\n",
        "        Dense(2, activation='softmax'),\n",
        "    ], name=\"classifier\")\n",
        "    optimizer = optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
        "    model.compile(optimizer, 'binary_crossentropy', ['accuracy'])\n",
        "    return model\n",
        "\n",
        "classifier = create_classifier((x.shape[1],))\n",
        "\n",
        "training = classifier.fit(X_train, y_train, batch_size=32, epochs=200, verbose=0,\n",
        "                          validation_data=(X_test, y_test),)\n",
        "print(f\"Training: loss={training.history['loss'][-1]:.4f}, \"\n",
        "      f\"accuracy={training.history['accuracy'][-1]:.4f}\")\n",
        "print(f\"Validation: loss={training.history['val_loss'][-1]:.4f}, \"\n",
        "      f\"accuracy={training.history['val_accuracy'][-1]:.4f}\")\n",
        "\n",
        "classifier.save(f\"{EXPERIMENT_PATH}/classifier.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gY6FCuwuZ75"
      },
      "source": [
        "## Estimate density with the reconstruction error of a (denoising) autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHvMh2YG3hRK",
        "outputId": "f44437fa-8c44-43c9-8b90-088cfeb07938"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 0.2337\n",
            "Validation loss: 0.2504\n",
            "{'reconstruction_error': '1.120 ± 0.137',\n",
            " 'reconstruction_error_noise': '1.151 ± 0.035'}\n"
          ]
        }
      ],
      "source": [
        "def add_noise(x, noise_factor=1e-6):\n",
        "    x_noisy = x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x.shape) \n",
        "    return x_noisy\n",
        "\n",
        "    \n",
        "def create_autoencoder(in_shape=(x.shape[1],)):\n",
        "    input_ = Input(shape=in_shape) \n",
        "\n",
        "    x = Dense(32, activation=\"relu\")(input_)\n",
        "    encoded = Dense(8)(x)\n",
        "    x = Dense(32, activation=\"relu\")(encoded)\n",
        "    decoded = Dense(in_shape[0], activation=\"tanh\")(x)\n",
        "\n",
        "    autoencoder = Model(input_, decoded)\n",
        "    optimizer = optimizers.Nadam()\n",
        "    autoencoder.compile(optimizer, 'mse')\n",
        "    return autoencoder\n",
        "\n",
        "autoencoder = create_autoencoder()\n",
        "training = autoencoder.fit(\n",
        "    add_noise(X_train), X_train, epochs=100, batch_size=32, shuffle=True, \n",
        "    validation_data=(X_test, X_test), verbose=0\n",
        ")\n",
        "print(f\"Training loss: {training.history['loss'][-1]:.4f}\")\n",
        "print(f\"Validation loss: {training.history['val_loss'][-1]:.4f}\")\n",
        "\n",
        "n_samples = 1000\n",
        "# Compute the reconstruction error of noise data\n",
        "samples = np.random.randn(n_samples, X_train.shape[1])\n",
        "reconstruction_error_noise = compute_reconstruction_error(samples, autoencoder)\n",
        "\n",
        "# Save and print the autoencoder metrics\n",
        "reconstruction_error = compute_reconstruction_error(X_test, autoencoder)\n",
        "autoencoder_metrics = {\n",
        "    \"reconstruction_error\": format_metric(reconstruction_error),\n",
        "    \"reconstruction_error_noise\": format_metric(reconstruction_error_noise),\n",
        "}\n",
        "json.dump(autoencoder_metrics, open(f\"{EXPERIMENT_PATH}/autoencoder_metrics.json\", \"w\"))\n",
        "pprint(autoencoder_metrics)\n",
        "\n",
        "autoencoder.save(f\"{EXPERIMENT_PATH}/autoencoder.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JcccJKG87kU"
      },
      "source": [
        "## Regularized Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dA5sU3Pf1k5",
        "outputId": "d973d943-cddd-43ef-dcd1-e27ac2ea412a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Produced explanation in 1.95 seconds \n",
            "Original prediction: 0 with probability 0.833\n",
            "Counterfactual prediction: 1 with probability 0.524\n",
            "Suggested perturbations: [ 0.35  0.39  0.39  0.39 -0.32  0.    0.    0.  ]\n"
          ]
        }
      ],
      "source": [
        "from alibi.explainers import CounterFactual\n",
        "\n",
        "shape = (1,) + X_train.shape[1:]\n",
        "feature_range = (X_train.min(), X_train.max())\n",
        "\n",
        "cf = CounterFactual(classifier, shape=shape, target_proba=1.0, tol=0.5,\n",
        "                    target_class=DESIRED_CLASS, max_iter=100, lam_init=0.001,\n",
        "                    max_lam_steps=5, learning_rate_init=0.1,\n",
        "                    feature_range=feature_range)\n",
        "\n",
        "sample = X_test[0]\n",
        "\n",
        "t_initial = time.time()\n",
        "explanation = cf.explain(np.expand_dims(sample, axis=0))\n",
        "print(f\"Produced explanation in {time.time() - t_initial:.2f} seconds \")\n",
        "\n",
        "y_prob = classifier.predict(np.expand_dims(sample, axis=0))[0]\n",
        "print(f'Original prediction: {y_prob.argmax()} with probability {y_prob.max():.3f}')\n",
        "\n",
        "pred_class = explanation.cf['class']\n",
        "proba = explanation.cf['proba'][0][pred_class]\n",
        "print(f'Counterfactual prediction: {pred_class} with probability {proba:.3f}')\n",
        "\n",
        "perturbations = (explanation.cf['X'] - sample)[0]\n",
        "perturbations[-len(immutable_features):] = 0.\n",
        "print(f\"Suggested perturbations: {perturbations}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "EXJ-JYqBGmxC",
        "outputId": "fec2b652-7a53-4b72-f3b9-e482e58f7888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1-th iteration at 2020-09-17 04:57:43.519545\n",
            "21-th iteration at 2020-09-17 04:58:11.216447\n",
            "41-th iteration at 2020-09-17 04:58:37.325165\n",
            "61-th iteration at 2020-09-17 04:59:05.829140\n",
            "81-th iteration at 2020-09-17 04:59:32.625520\n",
            "101-th iteration at 2020-09-17 04:59:57.687546\n",
            "121-th iteration at 2020-09-17 05:00:25.043526\n",
            "141-th iteration at 2020-09-17 05:00:50.304196\n",
            "154-th iteration at 2020-09-17 05:01:06.863386\n",
            "Metrics before immutable features projection:\n",
            "{'latency': '1328.412 ± 14.921',\n",
            " 'latency_batch': '204575.454',\n",
            " 'prediction_gain': '0.323 ± 0.048',\n",
            " 'reconstruction_error': '1.618 ± 0.204',\n",
            " 'sparsity': '2.602 ± 0.311'}\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics after immutable features projection:\n",
            "{'latency': '1328.412 ± 14.921',\n",
            " 'latency_batch': '204575.454',\n",
            " 'prediction_gain': '0.266 ± 0.049',\n",
            " 'reconstruction_error': '1.582 ± 0.205',\n",
            " 'sparsity': '1.968 ± 0.300'}\n"
          ]
        }
      ],
      "source": [
        "samples = X_test \n",
        "\n",
        "latencies = np.empty(len(samples))\n",
        "counterfactuals = np.empty_like(samples)\n",
        "\n",
        "for i, sample in enumerate(samples):\n",
        "    if ((i % 20) == 0) or (i == (len(samples)-1)):\n",
        "        print(f\"Iteration {i} at {datetime.now()}\")\n",
        "    t_initial = time.time()\n",
        "    try:\n",
        "        explanation = cf.explain(np.expand_dims(sample, axis=0))\n",
        "        counterfactuals[i] = explanation.cf['X']\n",
        "    except (UnboundLocalError, TypeError):  # counterfactual search failed\n",
        "        print(f\"{i}-th sampled failed\")\n",
        "        counterfactuals[i] = sample\n",
        "    latencies[i] = 1000*(time.time() - t_initial)\n",
        "\n",
        "print(\"Metrics before immutable features projection:\")\n",
        "pprint(compute_metrics(samples, counterfactuals, latencies, classifier, autoencoder,\n",
        "                    batch_latency=None))\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Set immutable features to original values\n",
        "counterfactuals[:, len(mutable_features):] = samples[:, len(mutable_features):]\n",
        "\n",
        "print(\"Metrics after immutable features projection:\")\n",
        "save_experiment(\"rgd\", samples, counterfactuals, latencies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWMMH-btKLOB"
      },
      "source": [
        "## Counterfactual Search Guided by Prototypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YxnNtLuKOHA"
      },
      "outputs": [],
      "source": [
        "from alibi.explainers import CounterFactualProto\n",
        "\n",
        "shape = (1,) + X_train.shape[1:]\n",
        "feature_range = (X_train.min(), X_train.max())\n",
        "\n",
        "cf_proto = CounterFactualProto(\n",
        "    classifier, shape, use_kdtree=True, theta=10., feature_range=feature_range,\n",
        "    max_iterations=200, c_steps=10\n",
        ")\n",
        "cf_proto.fit(X_train, trustscore_kwargs=None);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o4wfCfsKcge",
        "outputId": "0805439a-2a64-47b5-9e8c-97698abea977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Produced explanation in 3.55 seconds \n",
            "Original prediction: 0 with probability 0.833\n",
            "Counterfactual prediction: 1 with probability 0.506\n",
            "Suggested perturbations: [-5.46e-08 -3.65e-10  3.04e-01 -2.61e-08 -6.28e-10  0.00e+00  0.00e+00\n",
            "  0.00e+00]\n"
          ]
        }
      ],
      "source": [
        "sample = X_test[0]\n",
        "\n",
        "\n",
        "t_initial = time.time()\n",
        "explanation = cf_proto.explain(\n",
        "    np.expand_dims(sample, axis=0), k=5, k_type='mean', target_class=[DESIRED_CLASS]\n",
        ")\n",
        "\n",
        "print(f\"Produced explanation in {time.time() - t_initial:.2f} seconds \")\n",
        "\n",
        "y_prob = classifier.predict(np.expand_dims(sample, axis=0))[0]\n",
        "print(f'Original prediction: {y_prob.argmax()} with probability {y_prob.max():.3f}')\n",
        "\n",
        "pred_class = explanation.cf['class']\n",
        "proba = explanation.cf['proba'][0][pred_class]\n",
        "print(f'Counterfactual prediction: {pred_class} with probability {proba:.3f}')\n",
        "\n",
        "perturbations = (explanation.cf['X'] - sample)[0]\n",
        "perturbations[-len(immutable_features):] = 0.\n",
        "print(f\"Suggested perturbations: {perturbations}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "62zJUpDjKin9",
        "outputId": "6d825fb6-e247-47da-dfe0-3f3cd54caa82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1-th iteration at 2020-09-17 05:01:15.294025\n",
            "21-th iteration at 2020-09-17 05:02:16.691610\n",
            "41-th iteration at 2020-09-17 05:03:18.540155\n",
            "61-th iteration at 2020-09-17 05:04:21.173208\n",
            "81-th iteration at 2020-09-17 05:05:24.615457\n",
            "101-th iteration at 2020-09-17 05:06:28.014770\n",
            "121-th iteration at 2020-09-17 05:07:31.594086\n",
            "141-th iteration at 2020-09-17 05:08:34.903332\n",
            "154-th iteration at 2020-09-17 05:09:16.161087\n",
            "Metrics before immutable features projection:\n",
            "{'latency': '3142.089 ± 13.944',\n",
            " 'latency_batch': '483881.636',\n",
            " 'prediction_gain': '0.212 ± 0.030',\n",
            " 'reconstruction_error': '0.915 ± 0.104',\n",
            " 'sparsity': '1.696 ± 0.269'}\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics after immutable features projection:\n",
            "{'latency': '3142.089 ± 13.944',\n",
            " 'latency_batch': '483881.636',\n",
            " 'prediction_gain': '0.147 ± 0.024',\n",
            " 'reconstruction_error': '0.961 ± 0.111',\n",
            " 'sparsity': '1.198 ± 0.200'}\n"
          ]
        }
      ],
      "source": [
        "verbose = False\n",
        "samples = X_test\n",
        "\n",
        "latencies = np.empty(len(samples))\n",
        "counterfactuals = np.empty_like(samples)\n",
        "for i, sample in enumerate(samples):\n",
        "    if ((i % 20) == 0) or (i == (len(samples)-1)):\n",
        "        print(f\"{i+1}-th iteration at {datetime.now()}\")\n",
        "    t_initial = time.time()\n",
        "    try:\n",
        "        explanation = cf_proto.explain(np.expand_dims(sample, axis=0), k=20, \n",
        "                                       k_type='mean', target_class=[DESIRED_CLASS])\n",
        "        counterfactuals[i] = explanation.cf['X']\n",
        "    except (UnboundLocalError, TypeError) as e:  # counterfactual search failed\n",
        "        if verbose:\n",
        "            print(f\"{i}-th sampled failed\")\n",
        "        counterfactuals[i] = sample\n",
        "    latencies[i] = 1000*(time.time() - t_initial)\n",
        "\n",
        "print(\"Metrics before immutable features projection:\")\n",
        "pprint(compute_metrics(samples, counterfactuals, latencies, classifier, autoencoder,\n",
        "                    batch_latency=None))\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Set immutable features to original values\n",
        "counterfactuals[:, len(mutable_features):] = samples[:, len(mutable_features):]\n",
        "\n",
        "print(\"Metrics after immutable features projection:\")\n",
        "save_experiment(\"csgp\", samples, counterfactuals, latencies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwoisov75MsD"
      },
      "source": [
        "## GAN-based counterfactual search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi9faGZ42qRR"
      },
      "outputs": [],
      "source": [
        "def generate_fake_samples(x, generator):\n",
        "    \"\"\"Use the input generator to generate samples.\"\"\"\n",
        "    return generator.predict(x)\n",
        "\n",
        "def data_stream(x, y=None, batch_size=500):\n",
        "    \"\"\"Generate batches until exhaustion of the input data.\"\"\"\n",
        "    n_train = x.shape[0]\n",
        "    if y is not None:\n",
        "        assert n_train == len(y)\n",
        "    n_complete_batches, leftover = divmod(n_train, batch_size)\n",
        "    n_batches = n_complete_batches + bool(leftover)\n",
        "\n",
        "    perm = np.random.permutation(n_train)\n",
        "    for i in range(n_batches):\n",
        "        batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "        if y is not None:\n",
        "            output = (x[batch_idx], y[batch_idx])\n",
        "        else:\n",
        "            output = x[batch_idx]\n",
        "        yield output\n",
        "\n",
        "\n",
        "def infinite_data_stream(x, y=None, batch_size=500):\n",
        "    \"\"\"Infinite batch generator.\"\"\"\n",
        "    batches = data_stream(x, y, batch_size=batch_size)\n",
        "    while True:\n",
        "        try:\n",
        "            yield next(batches)\n",
        "        except StopIteration:\n",
        "            batches = data_stream(x, y, batch_size=batch_size)\n",
        "            yield next(batches)\n",
        "\n",
        "def create_generator(in_shape=(x_train.shape[1],), residuals=True):\n",
        "    \"\"\"Define and compile the residual generator of the CounteRGAN.\"\"\"\n",
        "    generator_input = Input(shape=in_shape, name='generator_input')\n",
        "    generator = Dense(64, activation='relu')(generator_input)\n",
        "    generator = Dense(32, activation='relu')(generator)\n",
        "    generator = Dense(64, activation='relu')(generator)\n",
        "    generator = Dense(in_shape[0], activation='tanh')(generator)\n",
        "    generator_output = ActivityRegularization(l1=0., l2=1e-6)(generator)\n",
        "    \n",
        "    if residuals:\n",
        "        generator_output = Add(name=\"output\")([generator_input, generator_output])\n",
        "\n",
        "    return Model(inputs=generator_input, outputs=generator_output)\n",
        "\n",
        "\n",
        "def create_discriminator(in_shape=(X_train.shape[1],)):\n",
        "    \"\"\" Define a neural network binary classifier to classify real and generated \n",
        "    examples.\"\"\"\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=in_shape),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation='sigmoid'),\n",
        "    ], name=\"discriminator\")\n",
        "    optimizer = optimizers.Adam(lr=0.0005, beta_1=0.5, decay=1e-8)\n",
        "    model.compile(optimizer, 'binary_crossentropy', ['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def define_countergan(generator, discriminator, classifier, \n",
        "                      input_shape=(X_train.shape[1],)):\n",
        "    \"\"\"Combine a generator, discriminator, and fixed classifier into the CounteRGAN.\"\"\"\n",
        "    discriminator.trainable = False\n",
        "    classifier.trainable = False\n",
        "\n",
        "    countergan_input = Input(shape=input_shape, name='countergan_input')\n",
        "  \n",
        "    x_generated = generator(countergan_input)\n",
        "\n",
        "    countergan = Model(\n",
        "        inputs=countergan_input, \n",
        "        outputs=[discriminator(x_generated), classifier(x_generated)]\n",
        "    )\n",
        "        \n",
        "    optimizer = optimizers.RMSprop(lr=2e-4, decay=1e-8)\n",
        "    countergan.compile(optimizer, [\"binary_crossentropy\", \"categorical_crossentropy\"])\n",
        "    return countergan\n",
        "\n",
        "\n",
        "def define_weighted_countergan(generator, discriminator, \n",
        "                               input_shape=(X_train.shape[1],)):\n",
        "    \"\"\"Combine a generator and a discriminator for the weighted version of the \n",
        "    CounteRGAN.\"\"\"\n",
        "    discriminator.trainable = False\n",
        "    classifier.trainable = False\n",
        "    countergan_input = Input(shape=input_shape, name='countergan_input')\n",
        "  \n",
        "    x_generated = generator(countergan_input)\n",
        "\n",
        "    countergan = Model(inputs=countergan_input, outputs=discriminator(x_generated))\n",
        "    optimizer = optimizers.RMSprop(lr=5e-4, decay=1e-8)\n",
        "    countergan.compile(optimizer, \"binary_crossentropy\")  \n",
        "    return countergan\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufnw6FKdPpa2"
      },
      "outputs": [],
      "source": [
        "def train_countergan(n_discriminator_steps, n_generator_steps, n_training_iterations,\n",
        "                     classifier, discriminator, generator, batches, \n",
        "                     weighted_version=False):\n",
        "    \"\"\" Main function: train the CounteRGAN\"\"\"\n",
        "    def check_divergence(x_generated):\n",
        "        return np.all(np.isnan(x_generated))\n",
        "\n",
        "    def print_training_information(generator, classifier, X_test, iteration):\n",
        "        X_gen = generator.predict(X_test)\n",
        "        clf_pred_test = classifier.predict(X_test)\n",
        "        clf_pred = classifier.predict(X_gen)\n",
        "\n",
        "        delta_clf_pred = (clf_pred - clf_pred_test)[:, DESIRED_CLASS]\n",
        "        y_target = to_categorical([DESIRED_CLASS] * len(clf_pred), \n",
        "                                  num_classes=N_CLASSES)\n",
        "        print('='*88)\n",
        "        print(f\"Training iteration {iteration} at {datetime.now()}\")\n",
        "        \n",
        "        \n",
        "        reconstruction_error = np.mean(compute_reconstruction_error(X_gen, autoencoder))\n",
        "        print(f\"Autoencoder reconstruction error (infinity to 0): {reconstruction_error:.3f}\")\n",
        "        print(f\"Counterfactual prediction gain (0 to 1): {delta_clf_pred.mean():.3f}\")\n",
        "        print(f\"Sparsity (L1, infinity to 0): {np.mean(np.abs(X_gen-X_test)):.3f}\")\n",
        "\n",
        "    if weighted_version:\n",
        "        countergan = define_weighted_countergan(generator, discriminator)\n",
        "    else:\n",
        "        countergan = define_countergan(generator, discriminator, classifier)\n",
        "\n",
        "    for iteration in range(n_training_iterations):\n",
        "        if iteration > 0:\n",
        "            x_generated = generator.predict(x_fake_input)\n",
        "            if check_divergence(x_generated):\n",
        "                print(\"Training diverged with the following loss functions:\")\n",
        "                print(discrim_loss_1, discrim_accuracy, gan_loss, \n",
        "                    discrim_loss, discrim_loss_2, clf_loss)\n",
        "                break\n",
        "\n",
        "        # Periodically print and plot training information \n",
        "        if (iteration % 1000 == 0) or (iteration == n_training_iterations - 1):\n",
        "            print_training_information(generator, classifier, X_test, iteration)\n",
        "\n",
        "        # Train the discriminator\n",
        "        discriminator.trainable = True\n",
        "        for _ in range(n_discriminator_steps):\n",
        "            x_fake_input, _ = next(batches)\n",
        "            x_fake = generate_fake_samples(x_fake_input, generator)\n",
        "            x_real = x_fake_input\n",
        "\n",
        "            x_batch = np.concatenate([x_real, x_fake])\n",
        "            y_batch = np.concatenate([np.ones(len(x_real)), np.zeros(len(x_fake))])\n",
        "            \n",
        "            # Shuffle real and fake examples\n",
        "            p = np.random.permutation(len(y_batch))\n",
        "            x_batch, y_batch = x_batch[p], y_batch[p]\n",
        "\n",
        "            if weighted_version:\n",
        "                classifier_scores = classifier.predict(x_batch)[:, DESIRED_CLASS]\n",
        "                \n",
        "                # The following update to the classifier scores is needed to have the \n",
        "                # same order of magnitude between real and generated samples losses\n",
        "                real_samples = np.where(y_batch == 1.)\n",
        "                average_score_real_samples = np.mean(classifier_scores[real_samples])\n",
        "                classifier_scores[real_samples] /= average_score_real_samples\n",
        "                \n",
        "                fake_samples = np.where(y_batch == 0.)\n",
        "                classifier_scores[fake_samples] = 1.\n",
        "\n",
        "                discriminator.train_on_batch(\n",
        "                    x_batch, y_batch, sample_weight=classifier_scores\n",
        "                )\n",
        "            else:\n",
        "                discriminator.train_on_batch(x_batch, y_batch)\n",
        "\n",
        "        # Train the generator \n",
        "        discriminator.trainable = False\n",
        "        for _ in range(n_generator_steps):\n",
        "            x_fake_input, _ = next(batches)\n",
        "            y_fake = np.ones(len(x_fake_input))\n",
        "            if weighted_version:\n",
        "                countergan.train_on_batch(x_fake_input, y_fake)\n",
        "            else:\n",
        "                y_target = to_categorical([DESIRED_CLASS] * len(x_fake_input), \n",
        "                                          num_classes=N_CLASSES)\n",
        "                countergan.train_on_batch(x_fake_input, [y_fake, y_target])\n",
        "    return countergan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpaZptCP2k_U"
      },
      "source": [
        "## Counterfactual search with a regular GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "L4PL01njRnV9",
        "outputId": "dbaea06d-6f95-4bf7-c02e-15daaeed5164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================\n",
            "Training iteration 0 at 2020-09-17 05:29:44.184846\n",
            "Autoencoder reconstruction error (infinity to 0): 0.401\n",
            "Counterfactual prediction gain (0 to 1): 0.069\n",
            "Sparsity (L1, infinity to 0): 0.777\n",
            "========================================================================================\n",
            "Training iteration 1000 at 2020-09-17 05:30:53.071830\n",
            "Autoencoder reconstruction error (infinity to 0): 0.384\n",
            "Counterfactual prediction gain (0 to 1): -0.045\n",
            "Sparsity (L1, infinity to 0): 1.110\n",
            "========================================================================================\n",
            "Training iteration 1999 at 2020-09-17 05:31:52.525108\n",
            "Autoencoder reconstruction error (infinity to 0): 0.499\n",
            "Counterfactual prediction gain (0 to 1): -0.059\n",
            "Sparsity (L1, infinity to 0): 1.074\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics before immutable features projection:\n",
            "{'latency': '1.681 ± 0.056',\n",
            " 'latency_batch': '258.897',\n",
            " 'prediction_gain': '-0.051 ± 0.052',\n",
            " 'reconstruction_error': '0.514 ± 0.012',\n",
            " 'sparsity': '8.623 ± 0.383'}\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics after immutable features projection:\n",
            "{'latency': '1.681 ± 0.056',\n",
            " 'latency_batch': '258.897',\n",
            " 'prediction_gain': '-0.126 ± 0.042',\n",
            " 'reconstruction_error': '0.641 ± 0.080',\n",
            " 'sparsity': '5.181 ± 0.315'}\n"
          ]
        }
      ],
      "source": [
        "discriminator = create_discriminator()\n",
        "generator = create_generator(residuals=False)\n",
        "batches = infinite_data_stream(X_train, y_train, batch_size=256)\n",
        "\n",
        "method_name = \"regular_gan\"\n",
        "countergan = train_countergan(2, 4, 2000, classifier, discriminator, generator, batches)\n",
        "\n",
        "t_initial = time.time()\n",
        "counterfactuals = generator.predict(X_test)\n",
        "batch_latency = 1000*(time.time() - t_initial)\n",
        "\n",
        "latencies = np.zeros(len(X_test))\n",
        "for i, x in enumerate(X_test):\n",
        "    t_initial = time.time()\n",
        "    _ = generator.predict(np.expand_dims(x, axis=0))\n",
        "    latencies[i] = 1000*(time.time() - t_initial)\n",
        "\n",
        "print(\"-\"*80)\n",
        "print(\"Metrics before immutable features projection:\")\n",
        "pprint(compute_metrics(samples, counterfactuals, latencies, classifier, autoencoder,\n",
        "                    batch_latency=None))\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Set immutable features to original values\n",
        "counterfactuals[:, len(mutable_features):] = samples[:, len(mutable_features):]\n",
        "\n",
        "print(\"Metrics after immutable features projection:\")\n",
        "save_experiment(method_name, X_test, counterfactuals, latencies, batch_latency)\n",
        "\n",
        "generator.save(f\"{EXPERIMENT_PATH}/{method_name}/generator.h5\", save_format='h5')\n",
        "discriminator.save(f\"{EXPERIMENT_PATH}/{method_name}/discriminator.h5\", save_format='h5')\n",
        "countergan.save(f\"{EXPERIMENT_PATH}/{method_name}/countergan.h5\", save_format='h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7IvGXenSWL-"
      },
      "source": [
        "## CounteRGAN: first formulation for differentiable classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "mNQmxFS5SXIH",
        "outputId": "8ab0b191-abd2-44f3-ecd6-f980df21bd1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================\n",
            "Training iteration 0 at 2020-09-17 05:27:28.122947\n",
            "Autoencoder reconstruction error (infinity to 0): 1.105\n",
            "Counterfactual prediction gain (0 to 1): -0.039\n",
            "Sparsity (L1, infinity to 0): 0.115\n",
            "========================================================================================\n",
            "Training iteration 1000 at 2020-09-17 05:28:37.563724\n",
            "Autoencoder reconstruction error (infinity to 0): 1.383\n",
            "Counterfactual prediction gain (0 to 1): 0.260\n",
            "Sparsity (L1, infinity to 0): 0.481\n",
            "========================================================================================\n",
            "Training iteration 1999 at 2020-09-17 05:29:35.901126\n",
            "Autoencoder reconstruction error (infinity to 0): 1.377\n",
            "Counterfactual prediction gain (0 to 1): 0.254\n",
            "Sparsity (L1, infinity to 0): 0.484\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics before immutable features projection:\n",
            "{'latency': '1.506 ± 0.028',\n",
            " 'latency_batch': '231.963',\n",
            " 'prediction_gain': '0.253 ± 0.031',\n",
            " 'reconstruction_error': '1.378 ± 0.156',\n",
            " 'sparsity': '3.862 ± 0.158'}\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics after immutable features projection:\n",
            "{'latency': '1.506 ± 0.028',\n",
            " 'latency_batch': '231.963',\n",
            " 'prediction_gain': '0.166 ± 0.023',\n",
            " 'reconstruction_error': '1.229 ± 0.152',\n",
            " 'sparsity': '2.371 ± 0.105'}\n"
          ]
        }
      ],
      "source": [
        "discriminator = create_discriminator()\n",
        "generator = create_generator(residuals=True)\n",
        "batches = infinite_data_stream(X_train, y_train, batch_size=256)\n",
        "\n",
        "method_name = \"countergan\"\n",
        "countergan = train_countergan(2, 4, 2000, classifier, discriminator, generator, batches)\n",
        "\n",
        "t_initial = time.time()\n",
        "counterfactuals = generator.predict(X_test)\n",
        "batch_latency = 1000*(time.time() - t_initial)\n",
        "\n",
        "latencies = np.zeros(len(X_test))\n",
        "for i, x in enumerate(X_test):\n",
        "    t_initial = time.time()\n",
        "    _ = generator.predict(np.expand_dims(x, axis=0))\n",
        "    latencies[i] = 1000*(time.time() - t_initial)\n",
        "\n",
        "print(\"-\"*80)\n",
        "print(\"Metrics before immutable features projection:\")\n",
        "pprint(compute_metrics(samples, counterfactuals, latencies, classifier, autoencoder,\n",
        "                    batch_latency=None))\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Set immutable features to original values\n",
        "counterfactuals[:, len(mutable_features):] = samples[:, len(mutable_features):]\n",
        "\n",
        "print(\"Metrics after immutable features projection:\")\n",
        "save_experiment(method_name, X_test, counterfactuals, latencies, batch_latency)\n",
        "\n",
        "generator.save(f\"{EXPERIMENT_PATH}/{method_name}/generator.h5\", save_format='h5')\n",
        "discriminator.save(f\"{EXPERIMENT_PATH}/{method_name}/discriminator.h5\", save_format='h5')\n",
        "countergan.save(f\"{EXPERIMENT_PATH}/{method_name}/countergan.h5\", save_format='h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pf5VJKqTBfd"
      },
      "source": [
        "## CounteRGAN: second formulation for any classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "LKjswCOCTC-4",
        "outputId": "036b03e9-76ac-4f42-ac37-e85f0bbf28a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================\n",
            "Training iteration 0 at 2020-09-17 05:55:16.474251\n",
            "Autoencoder reconstruction error (infinity to 0): 1.179\n",
            "Counterfactual prediction gain (0 to 1): 0.021\n",
            "Sparsity (L1, infinity to 0): 0.121\n",
            "========================================================================================\n",
            "Training iteration 1000 at 2020-09-17 05:56:43.640654\n",
            "Autoencoder reconstruction error (infinity to 0): 1.365\n",
            "Counterfactual prediction gain (0 to 1): 0.170\n",
            "Sparsity (L1, infinity to 0): 0.424\n",
            "========================================================================================\n",
            "Training iteration 1999 at 2020-09-17 05:58:05.180140\n",
            "Autoencoder reconstruction error (infinity to 0): 1.367\n",
            "Counterfactual prediction gain (0 to 1): 0.212\n",
            "Sparsity (L1, infinity to 0): 0.439\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics before immutable features projection:\n",
            "{'latency': '10.295 ± 16.699',\n",
            " 'latency_batch': '1585.397',\n",
            " 'prediction_gain': '0.225 ± 0.027',\n",
            " 'reconstruction_error': '1.373 ± 0.152',\n",
            " 'sparsity': '3.541 ± 0.188'}\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics after immutable features projection:\n",
            "{'latency': '10.295 ± 16.699',\n",
            " 'latency_batch': '1585.397',\n",
            " 'prediction_gain': '0.143 ± 0.020',\n",
            " 'reconstruction_error': '1.240 ± 0.150',\n",
            " 'sparsity': '2.076 ± 0.120'}\n"
          ]
        }
      ],
      "source": [
        "discriminator = create_discriminator()\n",
        "generator = create_generator(residuals=True)\n",
        "batches = infinite_data_stream(X_train, y_train, batch_size=256)\n",
        "\n",
        "method_name = \"countergan-wt\"\n",
        "countergan = train_countergan(2, 3, 2000, classifier, discriminator, generator, \n",
        "                              batches, weighted_version=True)\n",
        "\n",
        "t_initial = time.time()\n",
        "counterfactuals = generator.predict(X_test)\n",
        "batch_latency = 1000*(time.time() - t_initial)\n",
        "\n",
        "latencies = np.zeros(len(X_test))\n",
        "for i, x in enumerate(X_test):\n",
        "    t_initial = time.time()\n",
        "    _ = countergan.predict(np.expand_dims(x, axis=0))\n",
        "    latencies[i] = 1000*(time.time() - t_initial)\n",
        "\n",
        "print(\"-\"*80)\n",
        "print(\"Metrics before immutable features projection:\")\n",
        "pprint(compute_metrics(samples, counterfactuals, latencies, classifier, autoencoder,\n",
        "                    batch_latency=None))\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Set immutable features to original values\n",
        "counterfactuals[:, len(mutable_features):] = samples[:, len(mutable_features):]\n",
        "\n",
        "print(\"Metrics after immutable features projection:\")\n",
        "save_experiment(method_name, X_test, counterfactuals, latencies, batch_latency)\n",
        "\n",
        "generator.save(f\"{EXPERIMENT_PATH}/{method_name}/generator.h5\", save_format='h5')\n",
        "discriminator.save(f\"{EXPERIMENT_PATH}/{method_name}/discriminator.h5\", save_format='h5')\n",
        "countergan.save(f\"{EXPERIMENT_PATH}/{method_name}/countergan.h5\", save_format='h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T-D0Jj0LVJM"
      },
      "source": [
        "## Generate the benchmark table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "5w-2mCNALc8O",
        "outputId": "5adf7fa7-ef41-43d5-df19-c6f1eabfabf2"
      },
      "outputs": [],
      "source": [
        "METHODS = [\"rgd\", \"csgp\", \"regular_gan\", \"countergan\", \"countergan-wt\"]\n",
        "METRIC_NAMES = [\n",
        "    \"prediction_gain\", \"reconstruction_error\", \"sparsity\", \"latency\", \"latency_batch\"\n",
        "]\n",
        "\n",
        "metrics = dict()\n",
        "for method in METHODS:\n",
        "    method_metrics = json.load(open(f\"{EXPERIMENT_PATH}/{method}/metrics.json\", \"r\"))\n",
        "    method_metrics = {k: v for k, v in method_metrics.items() if k in METRIC_NAMES}\n",
        "    metrics[method] = method_metrics\n",
        "\n",
        "metrics = pd.DataFrame(metrics)\n",
        "metrics.columns =  [\"RGD\",  \"CSGP\", \"GAN\", \"CounterGAN\", \"CounterRGAN-wt\"] \n",
        "\n",
        "metrics.index = [\n",
        "    \"↓ Realism\",\n",
        "    \"↑ Prediction gain\",\n",
        "    \"↓ Sparsity\",\n",
        "    \"↓ Latency (ms)\",\n",
        "    \"↓ Batch latency (ms)\",\n",
        "]\n",
        "\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKAfN55k9zjd"
      },
      "source": [
        "## Individual examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "s69m-GMnXxNf",
        "outputId": "facf23e6-0098-4842-b783-d5cc91218964"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BMI</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Pregnancies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>76.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>31.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.343</td>\n",
              "      <td>44.0</td>\n",
              "      <td>5.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>33.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.114</td>\n",
              "      <td>33.0</td>\n",
              "      <td>9.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>23.1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.476</td>\n",
              "      <td>46.0</td>\n",
              "      <td>8.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>64.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>35.8</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.545</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.440892e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>82.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>38.2</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.233</td>\n",
              "      <td>23.0</td>\n",
              "      <td>4.440892e-16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   BloodPressure  Insulin  ...   Age   Pregnancies\n",
              "0           76.0      0.0  ...  44.0  5.000000e+00\n",
              "1           56.0      0.0  ...  33.0  9.000000e+00\n",
              "2           72.0      0.0  ...  46.0  8.000000e+00\n",
              "3           64.0     66.0  ...  21.0  4.440892e-16\n",
              "4           82.0    125.0  ...  23.0  4.440892e-16\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "execution_count": 117,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "negative_idx = np.where(classifier.predict(x_test)[:, 1] < 0.5)[0]\n",
        "x_negative = X_test[negative_idx]\n",
        "original_features = standard_scaler.inverse_transform(x_negative)\n",
        "negative_df = pd.DataFrame(original_features, columns=features)\n",
        "negative_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "Ud0Dwe0GZXFT",
        "outputId": "5c247d8b-e9a7-42e2-95d0-35492781d306"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BMI</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Pregnancies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.245267</td>\n",
              "      <td>-0.168285</td>\n",
              "      <td>29.517547</td>\n",
              "      <td>0.265268</td>\n",
              "      <td>2.824298</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.590098</td>\n",
              "      <td>-10.985187</td>\n",
              "      <td>-4.899478</td>\n",
              "      <td>4.001734</td>\n",
              "      <td>-4.969263</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16.391856</td>\n",
              "      <td>-0.233478</td>\n",
              "      <td>-0.011665</td>\n",
              "      <td>-1.376831</td>\n",
              "      <td>3.959885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-2.812314</td>\n",
              "      <td>29.489317</td>\n",
              "      <td>7.159651</td>\n",
              "      <td>5.620124</td>\n",
              "      <td>9.216398</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-8.306026</td>\n",
              "      <td>60.743688</td>\n",
              "      <td>26.160375</td>\n",
              "      <td>5.256007</td>\n",
              "      <td>9.130106</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   BloodPressure    Insulin  ...  Age  Pregnancies\n",
              "0       1.245267  -0.168285  ...  0.0          0.0\n",
              "1      11.590098 -10.985187  ...  0.0          0.0\n",
              "2      16.391856  -0.233478  ...  0.0          0.0\n",
              "3      -2.812314  29.489317  ...  0.0          0.0\n",
              "4      -8.306026  60.743688  ...  0.0          0.0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "execution_count": 123,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counterfactuals = standard_scaler.inverse_transform(\n",
        "    generator.predict(x_test[negative_idx])\n",
        ")\n",
        "residuals = (counterfactuals - \n",
        "             standard_scaler.inverse_transform(x_test[negative_idx]))\n",
        "residuals_df = pd.DataFrame(residuals, columns=features)\n",
        "residuals_df[list(immutable_features)] = 0.\n",
        "residuals_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "qW9zy0bTYM5h",
        "outputId": "e74d92aa-3aa2-4d08-80d6-7a836c7b86c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "regular_gan\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "countergan\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "countergan-wt\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Initial values</th>\n",
              "      <th>RGD</th>\n",
              "      <th>CSGP</th>\n",
              "      <th>regular_gan</th>\n",
              "      <th>countergan</th>\n",
              "      <th>countergan-wt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BloodPressure</th>\n",
              "      <td>78.000000</td>\n",
              "      <td>-5.423836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.299530</td>\n",
              "      <td>-12.046440</td>\n",
              "      <td>15.693680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Insulin</th>\n",
              "      <td>22.000000</td>\n",
              "      <td>-18.605087</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.835007</td>\n",
              "      <td>-50.358517</td>\n",
              "      <td>26.346497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glucose</th>\n",
              "      <td>126.000000</td>\n",
              "      <td>9.543411</td>\n",
              "      <td>12.605164</td>\n",
              "      <td>-33.490791</td>\n",
              "      <td>30.281281</td>\n",
              "      <td>25.446625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>29.600000</td>\n",
              "      <td>2.230800</td>\n",
              "      <td>0.754640</td>\n",
              "      <td>8.812698</td>\n",
              "      <td>-0.522469</td>\n",
              "      <td>-5.058810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SkinThickness</th>\n",
              "      <td>27.000000</td>\n",
              "      <td>-1.940363</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.851517</td>\n",
              "      <td>3.495853</td>\n",
              "      <td>8.009716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <td>0.439000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pregnancies</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier Prediction</th>\n",
              "      <td>0.185442</td>\n",
              "      <td>0.576988</td>\n",
              "      <td>0.501705</td>\n",
              "      <td>0.401092</td>\n",
              "      <td>0.623442</td>\n",
              "      <td>0.585553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Initial values        RGD  ...  countergan  countergan-wt\n",
              "BloodPressure                  78.000000  -5.423836  ...  -12.046440      15.693680\n",
              "Insulin                        22.000000 -18.605087  ...  -50.358517      26.346497\n",
              "Glucose                       126.000000   9.543411  ...   30.281281      25.446625\n",
              "BMI                            29.600000   2.230800  ...   -0.522469      -5.058810\n",
              "SkinThickness                  27.000000  -1.940363  ...    3.495853       8.009716\n",
              "DiabetesPedigreeFunction        0.439000   0.000000  ...    0.000000       0.000000\n",
              "Age                            40.000000   0.000000  ...    0.000000       0.000000\n",
              "Pregnancies                     5.000000   0.000000  ...    0.000000       0.000000\n",
              "Classifier Prediction           0.185442   0.576988  ...    0.623442       0.585553\n",
              "\n",
              "[9 rows x 6 columns]"
            ]
          },
          "execution_count": 163,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_idx = 20\n",
        "sample = np.expand_dims(X_test[sample_idx], axis=0)\n",
        "\n",
        "def compute_residuals(sample, counterfactual):\n",
        "    counterfactual = standard_scaler.inverse_transform(counterfactual)\n",
        "    residuals = (counterfactual - standard_scaler.inverse_transform(sample))[0]\n",
        "    residuals[-len(immutable_features):] = 0\n",
        "    return residuals\n",
        "\n",
        "method_outputs = dict()\n",
        "\n",
        "d = negative_df.iloc[sample_idx].to_dict()\n",
        "d[\"Classifier Prediction\"] = classifier.predict(sample)[0][1]\n",
        "method_outputs[\"Initial values\"] = d\n",
        "\n",
        "\n",
        "explanation = cf.explain(sample)\n",
        "counterfactual = explanation.cf['X']\n",
        "scaled_counterfactual = compute_residuals(sample, counterfactual)\n",
        "d = {k: v for k, v in zip(features, list(scaled_counterfactual))}\n",
        "d[\"Classifier Prediction\"] = classifier.predict(counterfactual)[0][1]\n",
        "method_outputs[\"RGD\"] = d\n",
        "\n",
        "explanation = cf_proto.explain(sample, k=5, k_type='mean', target_class=[DESIRED_CLASS])\n",
        "counterfactual = explanation.cf['X']\n",
        "scaled_counterfactual = compute_residuals(sample, counterfactual)\n",
        "d = {k: v for k, v in zip(features, list(scaled_counterfactual))}\n",
        "d[\"Classifier Prediction\"] = classifier.predict(counterfactual)[0][1]\n",
        "method_outputs[\"CSGP\"] = d\n",
        "\n",
        "for method in [\"regular_gan\", \"countergan\", \"countergan-wt\"]:\n",
        "    generator = load_model(f\"{EXPERIMENT_PATH}/{method}/generator.h5\")\n",
        "    counterfactual = generator.predict(sample)\n",
        "    scaled_counterfactual = compute_residuals(sample, counterfactual)\n",
        "    d = {k: v for k, v in zip(features, list(scaled_counterfactual))}\n",
        "    d[\"Classifier Prediction\"] = classifier.predict(counterfactual)[0][1]\n",
        "    method_outputs[method] = d\n",
        "\n",
        "df = pd.DataFrame(method_outputs)\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "kdd_counterfactuals_diabetes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
